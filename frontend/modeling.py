# Importation des biblioth√®ques n√©cessaires pour la gestion des requ√™tes HTTP, la s√©rialisation JSON et l'interface utilisateur
import requests
import streamlit as st
import http.client
import json
import time

# D√©finition des constantes pour l'h√¥te et le port de l'API
API_HOST = "backend_serv"
API_PORT = 8000

# Fonction pour envoyer un prompt √† l'API et obtenir un identifiant de t√¢che
def generate_text(prompt):
    conn = http.client.HTTPConnection(API_HOST, API_PORT)  # Cr√©ation d'une connexion HTTP √† l'API
    headers = {"Content-type": "application/json"}  # D√©finition des en-t√™tes de la requ√™te
    data = {"prompt": prompt}  # Encapsulation du prompt dans un dictionnaire
    json_data = json.dumps(data)  # S√©rialisation des donn√©es en JSON
    conn.request("POST", "/generate/", json_data, headers)  # Envoi de la requ√™te POST
    response = conn.getresponse()  # Obtention de la r√©ponse
    result = json.loads(response.read().decode())  # D√©codage et d√©s√©rialisation de la r√©ponse JSON
    conn.close()  # Fermeture de la connexion
    return result["task_id"]  # Retour de l'ID de t√¢che

# Fonction pour obtenir le statut d'une t√¢che par son ID
def get_task_status(task_id):
    conn = http.client.HTTPConnection(API_HOST, API_PORT)  # Cr√©ation d'une connexion HTTP √† l'API
    conn.request("GET", f"/task/{task_id}")  # Envoi de la requ√™te GET
    response = conn.getresponse()  # Obtention de la r√©ponse
    status = response.read().decode()  # D√©codage de la r√©ponse
    conn.close()  # Fermeture de la connexion
    return status  # Retour du statut de la t√¢che

# Chemins vers les images des avatars pour l'interface utilisateur
av_us = 'avatar/man.png'
av_ass = 'avatar/lamini.png'

# Configuration de l'interface utilisateur avec Streamlit
st.title("ü¶ô AI Builders ChatBot")
st.subheader("For internal use only")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message(message["role"],avatar=av_us):
            st.markdown(message["content"])
    else:
        with st.chat_message(message["role"],avatar=av_ass):
            st.markdown(message["content"])



# React to user input
if prompt := st.chat_input("What is up?"):

    # Display user message in chat message container
    with st.chat_message("user", avatar=av_us):
        st.markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})


    # Display assistant response in chat message container
    with st.chat_message("assistant", avatar=av_ass):
        # For streaming
        message_placeholder = st.empty()
        full_response = ""

        task_id = generate_text(prompt)


        while True:
            status = get_task_status(task_id)
            if "Task not completed yet" not in status:
                print(status)
                break
            time.sleep(2)
        full_response += status               
        message_placeholder.markdown(status)

        # with requests.get(url, stream=True) as r:
        #     # printing response of each stream
        #     for chunk in r.iter_content(1024):
        #         response = chunk.decode("utf-8")
        #         full_response += response                
        #         message_placeholder.markdown(full_response + "‚ñå")
        #     message_placeholder.markdown(full_response)


    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": full_response})